<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    
<meta name="keywords" content="Qianyu Zhou, Shanghai Jiao Tong University"> 
<meta name="description" content="Qianyu Zhou's home page">
<meta name="google-site-verification" content="google1367f398cef8d4d4.html" />
<meta name="google-site-verification" content="google1367f398cef8d4d4.html" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title> Qianyu Zhou's homepage, SJTU</title>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');
</script>

<script>
   function showPubs(id) {
  if (id == 0) {
    document.getElementById('pubs').innerHTML = document.getElementById('pubs_selected').innerHTML;
    document.getElementById('select0').style = 'text-decoration:underline;color:#000000';
    document.getElementById('select1').style = '';
  } else {
    document.getElementById('pubs').innerHTML = document.getElementById('pubs_by_topic').innerHTML;
    document.getElementById('select1').style = 'text-decoration:underline;color:#000000';
    document.getElementById('select0').style = '';
  }
}

</script>
</head>
<body>

<nav class="navbar navbar-dark navbar-expand-lg fixed-top">
    <div id="layout-menu">
        <a href="#biography">Biography</a>
        <a href="#interests">Reserach Interests</a>
        <a href="#news">News</a>
        <a href="#pubs">Publication</a>
        <a href="#education">Education</a>
        <a href="#experience">Experience</a>
        <a href="#service">Services</a>
        <a href="#honors">Honors</a>
<!--         <a href="chinese_homepage.html">Chinese Homepage</a>
 -->    </div>
</nav>

<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1><font face="Arial"> Qianyu Zhou </font></h1>  <h1><font face="楷体"> 周千寓 </font></h1>
				</div>

				<h3><font face="Arial"> Ph.D </font></h3>
				<p><font face="Arial"> 
					<a href="https://dmcv.sjtu.edu.cn/" target="_blank"> Digital Media & Computer Vision (DMCV) Laboratory </a>  <br>
					<a href="https://www.cs.sjtu.edu.cn/en/" target="_blank"> Department of Computer Science and Engineering</a> <br>
					<a href="https://en.sjtu.edu.cn/" target="_blank"> Shanghai Jiao Tong University</a> <br>
					Shanghai, China <br>
					<br>
					Email: <a href="mailto:zhouqianyu@sjtu.edu.cn">zhouqianyu@sjtu.edu.cn</a> 
                    <span style="margin-right: 20px;"></span>
                    <a href="https://scholar.google.com/citations?hl=en&pli=1&user=KHg04fkAAAAJ">Google Scholar</a>
                    <span style="margin-right: 20px;"></span>
                    <a href="https://dblp.uni-trier.de/pid/232/4830-1.html">DBLP</a>
                    <span style="margin-right: 20px;"></span>
                    <a href="https://www.semanticscholar.org/author/Qianyu-Zhou/67190665">Semantic Scholar</a>
                    <span style="margin-right: 20px;"></span>
                    <a href="https://orcid.org/0000-0002-5331-050X">ORCID</a>
                    <br>
				</font></p>
			</td>
			<td>
				<img src="zqy.png" border="0" width="200"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>
 
<div id="biography">
<h2><font face="Arial"> Biography </font></h2>
<!-- <a name="Biography" /> -->
<p style="text-align:justify";><font face="Arial">
I got the Ph.D. degree at the <a href="https://www.cs.sjtu.edu.cn/en/" target="_blank">
Department of Computer Science and Engineering</a>, as well as <a href="https://dmcv.sjtu.edu.cn/" target="_blank">DMCV Lab</a>, <a href="https://en.sjtu.edu.cn/" target="_blank">Shanghai Jiao Tong University (SJTU)</a>, supervised by 
Prof. <a href="https://dmcv.sjtu.edu.cn/people/" target="_blank">
Lizhuang Ma</a>. I was selected into <a href="https://xsb.seiee.sjtu.edu.cn/xsb/info/35105.htm" target="_blank">
Wenjun Wu AI Honored Ph.D Class (Top 1%)</a> and <a href="https://www.gs.sjtu.edu.cn/post/detail/Z3MxNDc2" target="_blank">
Zhiyuan Honored Ph.D Program (The Highest Honor)</a> of SJTU, co-advised by Dr. <a href="https://shijianping.me/" target="_blank">
Jianping Shi</a>.
Before that, I received the B.Sc degree from the <a href="http://ccst.jlu.edu.cn/" target="_blank">College of Computer Science and Technology</a>, <a href="http://global.jlu.edu.cn/" target="_blank">Jilin University</a> in 2019. Here is my <a href="Qianyu_Zhou_CV.pdf">Curriculum Vitae</a>.

<!-- Currently, I am interested in computer vision, transfer learning and vision-language models, especially domain adaptation, domain generalization for image classification, object detection and semantic segmentation. -->

<!-- </font></p> 
<div class="navbar-collapse collapse">
<h2>
<a href="#Biography">Biography|</a>
<a href="#News">News|</a>
<a href="#Publications">Publications|</a>
<a href="#Services">Services|</a>  
<a href="#Experience">Experience</a>   
</h2>
</div>  -->

<!-- <p style="text-align:justify"><font face="Arial">
My research interest lies at the intersection of computer vision and machine learning.
Currently, I am working on (i) open-world perception and adaptation, (ii) out-of-domain generalization, and (iii) graph reasoning for vision tasks.
</font></p> -->
	
<!--<font color="red">Currently, I am working on domain generalization for semantic segmentation and object detection. I am looking for undergraduate or master students to engage in ongoing research papers. Don't hesitate to email me if you are interested.</font> <br><br>-->



<h2><font face="Arial"> Reserach Interests </h2>
<div id="interests">
<p><font face="Arial">Computer Vision, Machine Intelligence. </font></p> 
<ul>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        Transfer Learning, e.g., domain adaptation, domain generalization, and semi-supervised learning.  </p></li> 
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        Scene Understanding, e.g., semantic segmentation, object detection in images and videos.  </p></li> 
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        Multi-Modal Learning, e.g., vision-language models, 3D point cloud understanding.  </p></li>  
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        Biometrics, e.g., face anti-spoofing, presentation attack detection.  </p></li> 
</ul>
</div>


<h2><font face="Arial"> News </h2>
<div id="news" style="height: 330px; overflow: auto;">
<!-- <a name="News" /> -->
<ul>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [07/2024] Three papers are accepted to ACM MM 2024 (26.20% acceptance rate). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [07/2024] Two papers are accepted to ECCV 2024 (27.90% acceptance rate). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [06/2024] One paper is accepted to TCSVT (15% acceptance rate, IF=8.4). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [05/2024] I have successfully defended my PhD thesis!. </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [03/2024] One paper is accepted to TVCG (25% acceptance rate, IF=5.6). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [02/2024] Two papers are accepted to CVPR 2024 (23.58% acceptance rate). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [01/2024] Our paper TransVOD (TPAMI 2023) becomes the ESI Highly Cited Paper (Top 1%). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [12/2023] One paper is accepted to AAAI 2024 (23.75% acceptance rate). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [09/2023] I won the Yuanqing Yang Ph.D Fellowship (3 recipients per year in SJTU).  </p></li> 
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [08/2023] One paper won the Best Paper Award in CAD/Graphics 2023.  </p></li> 
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [06/2023] One paper is selected into Top 3% Paper Recognition of all papers accepted at ICASSP 2023.  </p></li> 
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [05/2023] One paper is accepted to the 1st Workshop on Vision-based InduStrial InspectiON (VISION) of CVPR 2023.  </p></li>  
<!--     <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [04/2023] I am invited to serve as a reviewer for ACM MM 2023. </p></li>   -->
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [03/2023] One paper is accepted to CVPR 2023 (25.78% acceptance rate). </p></li>
<!--     <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [02/2023] I am invited to serve as a reviewer for ICCV 2023. </p></li>   -->  
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [01/2023] One paper is accepted to TPAMI (9% acceptance rate, IF=23.6). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [11/2022] One paper is accepted to TPAMI (9% acceptance rate, IF=23.6). </p></li>	
<!--     <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [11/2022] I am invited to serve as a reviewer for CVPR 2023. </p></li> -->
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [09/2022] One paper is accepted to TCSVT (15% acceptance rate, IF=8.4). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [08/2022] I am invited to serve as a Programme Committee member of AAAI 2023. </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [07/2022] One paper is accepted to ECCV 2022 (26% acceptance rate). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [06/2022] One paper is accepted to ACM MM 2022 (27.9% acceptance rate). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [05/2022] One paper is accepted to Pattern Recognition (19% acceptance rate, IF=8.0). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [05/2022] One paper is accepted to CVIU (17% acceptance rate, IF=4.5). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [03/2022] One paper is selected as an oral presentation of ICME 2022 (top 14.5%). </p></li>
<!--     <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [03/2022] I am invited to serve as a reviewer for ECCV 2022. </p></li> -->
</ul>
</div>


<p id="publications">
<h2><font face="Arial"> Publications
    (<a href="" id="select0" onclick="showPubs(0); return false;">show selected</a> /
     <a href="" id="select1" onclick="showPubs(1); return false;">show all</a>)
</h2>
</p>
<!-- <div id="publication">
 -->


<p><font face="Arial"><a href="https://scholar.google.com/citations?hl=en&pli=1&user=KHg04fkAAAAJ">[Google Scholar]</a> (* indicates joint first author, and † indicates corresponding author) </font></p> 


<!-- <p>
Summay --> (18 papers as First Author): TPAMI x2, CVPR x3, ICCV x1, ECCV x2, ACM MM x4, AAAI x1, TCSVT/PR x3, others x2;</p>
<div id="pubs"></div>
<script id="pubs_selected">	
<ul>
    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_transvod_tpami_23.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          TransVOD: End-to-End Video Object Detection with Spatial-Temporal Transformers
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          <b>Qianyu Zhou</b>, Xiangtai Li, Lu He, Yibo Yang, Guangliang Cheng, Yunhai Tong, Lizhuang Ma, Dacheng Tao. 
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2023
          <p>
           [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9960850">paper</a>]
           [<a href="https://arxiv.org/pdf/2201.05047.pdf">arxiv</a>] 
           [<a href="https://ieeexplore.ieee.org/document/9960850">DOI</a>]
           [<a href="https://github.com/SJTU-LuHe/TransVOD">code1</a>]
           [<a href="https://github.com/qianyuzqy/TransVOD_Lite">code2</a>]
           [<a href="https://github.com/qianyuzqy/TransVOD_plusplus">code3</a>]
           [<a href="bibs/TPAMI_2023_TransVOD.txt">bib</a>]
          </p>
      </div>
    </div>


    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_sad_tpami_23.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          Self-Adversarial Disentangling for Specific Domain Adaptation
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          <b>Qianyu Zhou</b>, Qiqi Gu, Jiangmiao Pang,  Xuequan Lu, Lizhuang Ma. 
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2023
          <p>
           [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10024368">paper</a>]
           [<a href="https://arxiv.org/pdf/2108.03553.pdf">arxiv</a>] 
           [<a href="https://ieeexplore.ieee.org/document/10024368">DOI</a>]
           [<a href="bibs/TPAMI_2023_SAD.txt">bib</a>]
          </p>
      </div>
    </div>

    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_iadg_cvpr_23.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          Instance-Aware Domain Generalization for Face Anti-Spoofing
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          <b>Qianyu Zhou</b>, Ke-Yue Zhang, Taiping Yao, Xuequan Lu, Ran Yi,  Shouhong Ding, Lizhuang Ma. 
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023.
          <p>
             [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Instance-Aware_Domain_Generalization_for_Face_Anti-Spoofing_CVPR_2023_paper.pdf">paper</a>]
             [<a href="https://arxiv.org/pdf/2304.05640.pdf">arxiv</a>] 
             [<a href="https://doi.org/10.1109/CVPR52729.2023.01959">DOI</a>]
             [<a href="https://github.com/qianyuzqy/IADG">code</a>]
             [<a href="bibs/CVPR_2023_IADG.txt">bib</a>]
          </p>
      </div>
    </div>

    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_ttdg_cvpr_24.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          Test-Time Domain Generalization for Face Anti-Spoofing
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          <b>Qianyu Zhou</b>, Ke-Yue Zhang, Taiping Yao, Xuequan Lu, Shouhong Ding, Lizhuang Ma. 
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.
          <p>
             [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhou_Test-Time_Domain_Generalization_for_Face_Anti-Spoofing_CVPR_2024_paper.pdf">paper</a>]
             [<a href="https://arxiv.org/pdf/2403.19334.pdf">arxiv</a>]
             [<a href="bibs/CVPR_2024_TTDG.txt">bib</a>] 
          </p>
      </div>
    </div>

    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_camix_tcsvt_23.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          Context-Aware Mixup for Domain Adaptive Semantic Segmentation
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          <b>Qianyu Zhou</b>, Zhengyang Feng, Qiqi Gu, Jiangmiao Pang, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma. 
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), 2023.
          <p>
             [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9889681">paper</a>]
             [<a href="https://arxiv.org/pdf/2108.03557.pdf">arxiv</a>] 
             [<a href="https://ieeexplore.ieee.org/document/9889681">DOI</a>]
             [<a href="https://github.com/qianyuzqy/CAMix">code</a>]
             [<a href="bibs/TCSVT_2023_CAMix.txt">bib</a>]
          </p>
      </div>
    </div>


    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_amel_mm_22.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          Adaptive Mixture of Experts Learning for Generalizable Face Anti-Spoofing
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          <b>Qianyu Zhou</b>, Ke-Yue Zhang, Taiping Yao, Ran Yi,  Shouhong Ding, Lizhuang Ma. 
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          The 30th ACM International Conference on Multimedia (<b>ACM MM</b>), 2022.
          <p>
             [<a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3547769">paper</a>]
             [<a href="https://arxiv.org/pdf/2207.09868.pdf">arxiv</a>]
             [<a href="https://dl.acm.org/doi/10.1145/3503161.3547769">DOI</a>]
             [<a href="bibs/MM_2022_AMEL.txt">bib</a>]
          </p>
      </div>
    </div>

    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_gda_eccv_22.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          Generative Domain Adaptation for Face Anti-Spoofing
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          <b>Qianyu Zhou</b>, Ke-Yue Zhang, Taiping Yao, Ran Yi,  Shouhong Ding, Lizhuang Ma. 
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          European Conference on Computer Vision (<b>ECCV</b>), 2022.
          <p>
             [<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136650328.pdf">paper</a>]
           [<a href="https://arxiv.org/pdf/2207.10015.pdf">arxiv</a>] 
           [<a href="https://link.springer.com/chapter/10.1007/978-3-031-20065-6_20">DOI</a>]
           [<a href="bibs/ECCV_2022_GDA.txt">bib</a>]
          </p>
      </div>
    </div>

    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_basam_cvpr_24.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          Yiran Song*, <b>Qianyu Zhou*</b>, Xiangtai Li, Deng-Ping Fan, Xuequan Lu, Lizhuang Ma.
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.
          <p>
            [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Song_BA-SAM_Scalable_Bias-Mode_Attention_Mask_for_Segment_Anything_Model_CVPR_2024_paper.pdf">paper</a>]
            [<a href="https://openaccess.thecvf.com/content/CVPR2024/supplemental/Song_BA-SAM_Scalable_Bias-Mode_CVPR_2024_supplemental.pdf">supp</a>]
            [<a href="https://arxiv.org/pdf/2401.02317.pdf">arxiv</a>]
            [<a href="https://github.com/zongzi13545329/BA-SAM">code</a>]
            [<a href="bibs/CVPR_2024_BA-SAM.txt">bib</a>] 
          </p>
      </div>
    </div>


    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_dgmamba_mm_24.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          DGMamba: Domain Generalization via Generalized State Space Model
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          Shaocong Long*, <b>Qianyu Zhou*</b>, Xiangtai Li, Xuequan Lu, Chenhao Ying, Yuan Luo, Lizhuang Ma, Shuicheng Yan.
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          The 32nd ACM International Conference on Multimedia (<b>ACM MM</b>), 2024..
          <p>
            [<a href="https://arxiv.org/pdf/2404.07794.pdf">paper</a>]
            [<a href="https://arxiv.org/pdf/2404.07794.pdf">arxiv</a>]
            [<a href="https://github.com/longshaocong/DGMamba">code</a>] 
            [<a href="bibs/MM_2024_DGMamba.txt">bib</a>] 
          </p>
      </div>
    </div>


    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_adv_pruning_mm_24.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          Rethinking Impersonation and Dodging Attacks on Face Recognition Systems
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          Fengfan Zhou*, <b>Qianyu Zhou*</b>, Bangjie Yin, Hui Zheng, Xuequan Lu, Lizhuang Ma, Hefei Ling.
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          The 32nd ACM International Conference on Multimedia (<b>ACM MM</b>), 2024.
          <p>
            [<a href="https://arxiv.org/pdf/2401.08903">paper</a>]
            [<a href="https://arxiv.org/pdf/2401.08903">arxiv</a>]
            [<a href="bibs/MM_2024_Adv_Pruning.txt">bib</a>]
          </p>
      </div>
    </div>

    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_dmda_tcsvt_24.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          Rethinking Domain Generalization: Discriminability and Generalizability
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          Shaocong Long*, <b>Qianyu Zhou*</b>, Chenhao Ying, Lizhuang Ma, Yuan Luo.
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), 2024.
          <p>
            [<a href="https://ieeexplore.ieee.org/document/10583916">paper</a>]
            [<a href="https://arxiv.org/pdf/2309.16483.pdf">arxiv</a>]
            [<a href="https://github.com/longshaocong/DMDA">code</a>]
            [<a href="bibs/TCSVT_2024_DMDA.txt">bib</a>] 
          </p>
      </div>
    </div>

    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_dgpic_eccv_24.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          DG-PIC: Domain Generalized Point-In-Context Learning for Point Cloud Understanding
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          Jincen Jiang*, <b>Qianyu Zhou*</b>, Yuhang Li, Xuequan Lu, Meili Wang, Lizhuang Ma, Jian Chang, Jian J Zhang..
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          European Conference on Computer Vision (<b>ECCV</b>), 2024.
          <p>
             [<a href="https://arxiv.org/pdf/2407.08801">paper</a>]
             [<a href="https://arxiv.org/pdf/2407.08801">arxiv</a>]
             [<a href="https://github.com/Jinec98/DG-PIC">code</a>]
             [<a href="bibs/ECCV_2024_DGPIC.txt">bib</a>] 
          </p>
      </div>
    </div>

    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_pit_iccv_21.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          PIT: Position-Invariant Transform for Cross-FoV Domain Adaptation
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          Qiqi Gu*, <b>Qianyu Zhou*</b>, Minghao Xu, Zhengyang Feng, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma.
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2021.
          <p>
           [<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Gu_PIT_Position-Invariant_Transform_for_Cross-FoV_Domain_Adaptation_ICCV_2021_paper.pdf">paper</a>]
           [<a href="https://arxiv.org/pdf/2108.07142.pdf">arxiv</a>]
           [<a href="https://ieeexplore.ieee.org/document/9711500">DOI</a>] 
           [<a href="https://github.com/sheepooo/PIT-Position-Invariant-Transform">code</a>]
           [<a href="bibs/ICCV_2021_PIT.txt">bib</a>]
          </p>
      </div>
    </div>


    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_transvod_mm_21.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          End-to-End Video Object Detection with Spatial-Temporal Transformers
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          Lu He*, <b>Qianyu Zhou*</b>, Xiangtai Li*, Li Niu, Guangliang Cheng, Xiao Li, Wenxuan Liu, Yunhai Tong, Lizhuang Ma, Liqing Zhang.
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          The 29th ACM International Conference on Multimedia (<b>ACM MM</b>), 2021.
          <p>
           [<a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475285">paper</a>]
           [<a href="https://arxiv.org/pdf/2105.10920.pdf">arxiv</a>]
           [<a href="https://dl.acm.org/doi/10.1145/3474085.3475285">DOI</a>]
           [<a href="https://github.com/SJTU-LuHe/TransVOD">code</a>] 
           [<a href="bibs/MM_2021_TransVOD.txt">bib</a>]
          </p>
      </div>
    </div>

    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_dmt_pr_22.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          DMT: Dynamic Mutual Training for Semi-Supervised Learning
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          Zhengyang Feng*, <b>Qianyu Zhou*</b>, Qiqi Gu, Xin Tan, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma.
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          Patter Recognition (<b>PR</b>), 2022.
          <p>
            [<a href="https://www.sciencedirect.com/science/article/pii/S0031320322002588">paper</a>]
               [<a href="https://arxiv.org/pdf/2004.08514.pdf">arxiv</a>]
               [<a href="https://www.sciencedirect.com/science/article/pii/S0031320322002588">DOI</a>]
               [<a href="https://github.com/voldemortX/DST-CBC">code</a>]
               [<a href="bibs/PR_2022_DMT.txt">bib</a>]
          </p>
      </div>
    </div>

    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_cpabmm_aaai_24.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          Continuous Piecewise-Affine Based Motion Model for Image Animation
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          Hexiang Wang*, Fengqi Liu*, <b>Qianyu Zhou*</b>, Xin Tan, Ran Yi, Lizhuang Ma.
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2024.
          <p>
            [<a href="https://arxiv.org/pdf/2401.09146.pdf">paper</a>]
            [<a href="https://arxiv.org/pdf/2401.09146.pdf">arxiv</a>]
            [<a href="https://github.com/DevilPG/AAAI2024-CPABMM">code</a>]
            [<a href="bibs/AAAI_2024_CPABMM.txt">bib</a>] 
          </p>
      </div>
    </div>

    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:1px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px"><font face="Arial" size="3">
          <img src="imgs/fig_cloudmix_tvcg_24.png" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          CloudMix: Dual Mixup Consistency for Unpaired Point Cloud Completion
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          Fengqi Liu*, Jingyu Gong*, <b>Qianyu Zhou</b>, Xuequan Lu, Ran Yi, Yuan Xie, and Lizhuang Ma
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          IEEE Transactions on Visualization and Computer Graphics (<b>TVCG</b>), 2024.
          <p>
             [<a href="https://ieeexplore.ieee.org/document/10487003">paper</a>]
             [<a href="https://doi.org/10.1109/TVCG.2024.3383434">DOI</a>]
             [<a href="bibs/TVCG_2024_CloudMix.txt">bib</a>] 
          </p>
      </div>
    </div>

</ul>
</div>
</script>

<br>
<script id="pubs_by_topic">
<h3>2024:</h3>
<ul>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Test-Time Domain Generalization for Face Anti-Spoofing <br> 
         <i>   <b>Qianyu Zhou</b>, Ke-Yue Zhang, Taiping Yao, Xuequan Lu, Shouhong Ding, Lizhuang Ma. </i><br> 
           IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), pp. 175-187, June, 2024. <br>
         [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhou_Test-Time_Domain_Generalization_for_Face_Anti-Spoofing_CVPR_2024_paper.pdf">paper</a>]
         [<a href="https://arxiv.org/pdf/2403.19334.pdf">arxiv</a>]
         [<a href="bibs/CVPR_2024_TTDG.txt">bib</a>] 
      </font>
     </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model <br> 
         <i>   Yiran Song*, <b>Qianyu Zhou*</b>, Xiangtai Li, Deng-Ping Fan, Xuequan Lu, Lizhuang Ma. </i><br>
         IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), June, 2024. <br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Song_BA-SAM_Scalable_Bias-Mode_Attention_Mask_for_Segment_Anything_Model_CVPR_2024_paper.pdf">paper</a>]
        [<a href="https://openaccess.thecvf.com/content/CVPR2024/supplemental/Song_BA-SAM_Scalable_Bias-Mode_CVPR_2024_supplemental.pdf">supp</a>]
        [<a href="https://arxiv.org/pdf/2401.02317.pdf">arxiv</a>]
        [<a href="https://github.com/zongzi13545329/BA-SAM">code</a>]
        [<a href="bibs/CVPR_2024_BA-SAM.txt">bib</a>]  
        </font>
        </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            DGMamba: Domain Generalization via Generalized State Space Model <br> 
         <i>   Shaocong Long*, <b>Qianyu Zhou*</b>, Xiangtai Li, Xuequan Lu, Chenhao Ying, Yuan Luo, Lizhuang Ma, Shuicheng Yan. </i><br>
         The 32nd ACM International Conference on Multimedia (<b>ACM MM</b>), October, 2024. <br>
        [<a href="https://arxiv.org/pdf/2404.07794.pdf">paper</a>]
        [<a href="https://arxiv.org/pdf/2404.07794.pdf">arxiv</a>]
        [<a href="https://github.com/longshaocong/DGMamba">code</a>] 
        [<a href="bibs/MM_2024_DGMamba.txt">bib</a>]     
        </font>
        </p> </li>

        <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Rethinking Impersonation and Dodging Attacks on Face Recognition Systems <br> 
         <i>   Fengfan Zhou*, <b>Qianyu Zhou*</b>, Bangjie Yin, Hui Zheng, Xuequan Lu, Lizhuang Ma, Hefei Ling. </i><br>
        The 32nd ACM International Conference on Multimedia (<b>ACM MM</b>), October, 2024. <br>
        [<a href="https://arxiv.org/pdf/2401.08903">paper</a>]
        [<a href="https://arxiv.org/pdf/2401.08903">arxiv</a>]
        [<a href="bibs/MM_2024_Adv_Pruning.txt">bib</a>]
        </font>
        </p> </li>

        <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Emphasizing Semantic Consistency of Salient Posture for Speech-Driven Gesture Generation <br> 
         <i>   Fengqi Liu, Hexiang Wang, Jingyu Gong, Ran Yi, <b>Qianyu Zhou</b>, Xuequan Lu, Jiangbo Lu, Lizhuang Ma. </i><br>
        The 32nd ACM International Conference on Multimedia (<b>ACM MM</b>), October, 2024. <br>
        [<a href="">paper</a>]
        [<a href="">arxiv</a>]
        [<a href="">bib</a>]
        </font>
        </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            DG-PIC: Domain Generalized Point-In-Context Learning for Point Cloud Understanding <br> 
         <i>  Jincen Jiang*, <b>Qianyu Zhou*</b>, Yuhang Li, Xuequan Lu, Meili Wang, Lizhuang Ma, Jian Chang, Jian J Zhang. </i><br>
           European Conference on Computer Vision (<b>ECCV</b>), October, 2024. <br>
         [<a href="https://arxiv.org/pdf/2407.08801">paper</a>]
         [<a href="https://arxiv.org/pdf/2407.08801">arxiv</a>]
         [<a href="https://github.com/Jinec98/DG-PIC">code</a>]
         [<a href="bibs/ECCV_2024_DGPIC.txt">bib</a>] 
      </font>
     </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            TF-FAS: Twofold-Element Fine-Grained Semantic Guidance for Generalizable Face Anti-Spoofing <br> 
         <i>  Xudong Wang, Ke-Yue Zhang, Taiping Yao, <b>Qianyu Zhou</b>, Shouhong Ding, Pingyang Dai, Rongrong Ji. </i><br>
           European Conference on Computer Vision (<b>ECCV</b>), October, 2024. <br>
         [<a href="">paper</a>]
         [<a href="">arxiv</a>]
         [<a href="https://github.com/xudongww/TF-FAS">code</a>]
         [<a href="bibs/ECCV_2024_TF_FAS.txt">bib</a>] 
      </font>
     </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Rethinking Domain Generalization: Discriminability and Generalizability <br> 
         <i>   Shaocong Long*, <b>Qianyu Zhou*</b>, Chenhao Ying, Lizhuang Ma, Yuan Luo. </i><br>
        IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), 2024. <br>
        [<a href="https://arxiv.org/pdf/2309.16483.pdf">paper</a>]
        [<a href="https://arxiv.org/pdf/2309.16483.pdf">arxiv</a>]
        [<a href="https://github.com/longshaocong/DMDA">code</a>]
        [<a href="bibs/TCSVT_2024_DMDA.txt">bib</a>]     
        </font>
        </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Continuous Piecewise-Affine Based Motion Model for Image Animation <br> 
         <i>   Hexiang Wang*, Fengqi Liu*, <b>Qianyu Zhou*</b>, Xin Tan, Ran Yi, Lizhuang Ma. </i><br>
         AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2024. <br>
        [<a href="https://arxiv.org/pdf/2401.09146.pdf">paper</a>]
        [<a href="https://arxiv.org/pdf/2401.09146.pdf">arxiv</a>]
        [<a href="https://github.com/DevilPG/AAAI2024-CPABMM">code</a>]
        [<a href="bibs/AAAI_2024_CPABMM.txt">bib</a>]  
        </font>
        </p> </li>
           
        <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            CloudMix: Dual Mixup Consistency for Unpaired Point Cloud Completion <br> 
         <i>   Fengqi Liu*, Jingyu Gong*, <b>Qianyu Zhou</b>, Xuequan Lu, Ran Yi, Yuan Xie, and Lizhuang Ma </i><br>
         IEEE Transactions on Visualization and Computer Graphics (<b>TVCG</b>), 2024. <br>
         [<a href="https://ieeexplore.ieee.org/document/10487003">paper</a>]
         [<a href="https://doi.org/10.1109/TVCG.2024.3383434">DOI</a>]
         [<a href="bibs/TVCG_2024_CloudMix.txt">bib</a>]   
        </font>
        </p> </li>

       <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Diverse Target and Contribution Scheduling for Domain Generalization <br> 
         <i>   Shaocong Long*, <b>Qianyu Zhou*</b>, Chenhao Ying, Lizhuang Ma, Yuan Luo. </i><br>
         ArXiv preprint arXiv:2309.16460. <br>
        [<a href="https://arxiv.org/pdf/2309.16460.pdf">paper</a>]
        [<a href="https://arxiv.org/pdf/2309.16460.pdf">arxiv</a>]
        [<a href="https://github.com/longshaocong/DTCS">code</a>]
        [<a href="bibs/Arxiv_2024_DTCS.txt">bib</a>]     
        </font>
        </p> </li>

        <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            SimAda: A Simple Unified Framework for Adapting Segment Anything Model in Underperformed Scenes <br> 
         <i>   Yiran Song*, <b>Qianyu Zhou*</b>, Xuequan Lu, Zhiwen Shao, Lizhuang Ma. </i><br>
         ArXiv preprint arXiv:2401.17803. <br>
        [<a href="https://arxiv.org/pdf/2401.17803.pdf">paper</a>]
        [<a href="https://arxiv.org/pdf/2401.17803.pdf.pdf">arxiv</a>]
        [<a href="https://github.com/zongzi13545329/SimAda">code</a>] 
        [<a href="bibs/Arxiv_2024_SimAda.txt">bib</a>]
        </font>
        </p> </li>

        <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Adversarial Attacks on Both Face Recognition and Face Anti-spoofing Models <br> 
         <i>   Fengfan Zhou, <b>Qianyu Zhou</b>, Xiangtai Li, Xuequan Lu, Lizhuang Ma, Hefei Ling. </i><br>
         ArXiv preprint arXiv:2405.16940. <br>
        [<a href="https://arxiv.org/pdf/2405.16940">paper</a>]
        [<a href="https://arxiv.org/pdf/2405.16940">arxiv</a>]
        [<a href="bibs/Arxiv_2024_SDB.txt">bib</a>]
        </font>
        </p> </li>

        <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            MotionBooth: Motion-Aware Customized Text-to-Video Generation <br> 
         <i> Jianzong Wu, Xiangtai Li, Yanhong Zeng, Jiangning Zhang, <b>Qianyu Zhou</b>, Yining Li, Yunhai Tong, Kai Chen. </i><br>
         ArXiv preprint arXiv:2406.17758. <br>
        [<a href="https://arxiv.org/pdf/2406.17758">paper</a>]
        [<a href="https://arxiv.org/pdf/2406.17758">arxiv</a>]
        [<a href="https://github.com/jianzongwu/MotionBooth">code</a>] 
        [<a href="bibs/Arxiv_2024_MotionBooth.txt">bib</a>]
        </font>
        </p> </li>

</ul> 
<h3>2023:</h3>    
<ul>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            TransVOD: End-to-End Video Object Detection with Spatial-Temporal Transformers <br> 
         <i>   <b>Qianyu Zhou</b>, Xiangtai Li, Lu He, Yibo Yang, Guangliang Cheng, Yunhai Tong, Lizhuang Ma, Dacheng Tao. </i><br> 
         IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), vol. 45, no. 6, pp. 7853-7869, 2023. <br>
   [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9960850">paper</a>]
   [<a href="https://arxiv.org/pdf/2201.05047.pdf">arxiv</a>] 
   [<a href="https://ieeexplore.ieee.org/document/9960850">DOI</a>]
   [<a href="https://github.com/SJTU-LuHe/TransVOD">code1</a>]
   [<a href="https://github.com/qianyuzqy/TransVOD_Lite">code2</a>]
   [<a href="https://github.com/qianyuzqy/TransVOD_plusplus">code3</a>]
   [<a href="bibs/TPAMI_2023_TransVOD.txt">bib</a>]
   </font>
     </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Self-Adversarial Disentangling for Specific Domain Adaptation <br> 
         <i>   <b>Qianyu Zhou</b>, Qiqi Gu, Jiangmiao Pang,  Xuequan Lu, Lizhuang Ma. </i><br> 
         IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), vol. 45, no. 7, pp. 8954-8968, 2023. <br>
   [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10024368">paper</a>]
   [<a href="https://arxiv.org/pdf/2108.03553.pdf">arxiv</a>] 
   [<a href="https://ieeexplore.ieee.org/document/10024368">DOI</a>]
   [<a href="bibs/TPAMI_2023_SAD.txt">bib</a>]
   </font>
   </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Instance-Aware Domain Generalization for Face Anti-Spoofing <br> 
         <i>   <b>Qianyu Zhou</b>, Ke-Yue Zhang, Taiping Yao, Xuequan Lu, Ran Yi,  Shouhong Ding, Lizhuang Ma. </i><br> 
           IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), pp. 20453-20463, June, 2023. <br>
     [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Instance-Aware_Domain_Generalization_for_Face_Anti-Spoofing_CVPR_2023_paper.pdf">paper</a>]
     [<a href="https://arxiv.org/pdf/2304.05640.pdf">arxiv</a>] 
     [<a href="https://doi.org/10.1109/CVPR52729.2023.01959">DOI</a>]
     [<a href="https://github.com/qianyuzqy/IADG">code</a>]
     [<a href="bibs/CVPR_2023_IADG.txt">bib</a>]
      </font>
     </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Context-Aware Mixup for Domain Adaptive Semantic Segmentation <br> 
         <i>   <b>Qianyu Zhou</b>, Zhengyang Feng, Qiqi Gu, Jiangmiao Pang, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma. </i><br> 
           IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), vol. 33, no. 2, pp. 804-817, 2023. <br>
     [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9889681">paper</a>]
     [<a href="https://arxiv.org/pdf/2108.03557.pdf">arxiv</a>] 
     [<a href="https://ieeexplore.ieee.org/document/9889681">DOI</a>]
     [<a href="https://github.com/qianyuzqy/CAMix">code</a>]
     [<a href="bibs/TCSVT_2023_CAMix.txt">bib</a>]
     </font>
     </p> </li>
    

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Rethinking Implicit Neural Representations for Vision Learners <br> 
         <i>   Yiran Song, <b>Qianyu Zhou<sup>†</sup></b>, Lizhuang Ma<sup>†</sup>. </i><br> 
         IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>), June, 2023. <br>
         Top 3% Paper Recognition of all papers accepted at ICASSP 2023. <br>
   [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10094875">paper</a>]
   [<a href="https://arxiv.org/pdf/2211.12040.pdf">arxiv</a>]
   [<a href="https://ieeexplore.ieee.org/document/10094875">DOI</a>]
   [<a href="bibs/ICASSP_2023_IRNS.txt">bib</a>]
   </font>
   </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
           ZDL: Zero-shot Degradation Factor Learning for Robust and Efficient Image Enhancement <br> 
         <i>   Hao Yang, Haijun Sun, <b>Qianyu Zhou</b>, Ran Yi, Lizhuang Ma. </i><br> 
         The 18th International Conference on Computer-Aided Design and Computer Graphics (<b>CCF CAD/Graphics</b>), August, 2023. <br>
         Best Paper Award in CAD/Graphics 2023. <br>
   [<a href="https://link.springer.com/chapter/10.1007/978-981-99-9666-7_18">paper</a>]
   [<a href="https://link.springer.com/chapter/10.1007/978-981-99-9666-7_18">DOI</a>]
   [<a href="bibs/CADGraphics_2024_ZDL.txt">bib</a>]
   </font>
   </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
           Dynamic Sampling Dual Deformable Network for Online Video Instance Segmentation <br> 
           <i>   Yiran Song, <b>Qianyu Zhou</b>, Ran Yi, Zhiwen Shao, Lizhuang Ma. </i><br> 
         Journal of Zhejiang University (Engineering Science) in Chinese, 2023. <br>
   [<a href="">paper coming soon</a>]
   </font>
   </p> </li>


</ul>
<h3>2022:</h3>   
<ul>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Adaptive Mixture of Experts Learning for Generalizable Face Anti-Spoofing <br> 
         <i>   <b>Qianyu Zhou</b>, Ke-Yue Zhang, Taiping Yao, Ran Yi,  Shouhong Ding, Lizhuang Ma. </i><br> 
           The 30th ACM International Conference on Multimedia (<b>ACM MM</b>), pp. 6009-6018, October, 2022. <br>
     [<a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3547769">paper</a>]
     [<a href="https://arxiv.org/pdf/2207.09868.pdf">arxiv</a>]
     [<a href="https://dl.acm.org/doi/10.1145/3503161.3547769">DOI</a>]
     [<a href="bibs/MM_2022_AMEL.txt">bib</a>]
      </font>
     </p> </li>
   
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Generative Domain Adaptation for Face Anti-Spoofing  <br> 
     <i>   <b>Qianyu Zhou</b>, Ke-Yue Zhang, Taiping Yao, Ran Yi, Kekai Sheng, Shouhong Ding, Lizhuang Ma. </i><br> 
           European Conference on Computer Vision (<b>ECCV</b>), pp. 335-356, October, 2022. <br>
     [<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136650328.pdf">paper</a>]
   [<a href="https://arxiv.org/pdf/2207.10015.pdf">arxiv</a>] 
   [<a href="https://link.springer.com/chapter/10.1007/978-3-031-20065-6_20">DOI</a>]
   [<a href="bibs/ECCV_2022_GDA.txt">bib</a>]
   </font>
     </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Uncertainty-Aware Consistency Regularization for Cross-Domain Semantic Segmentation <br> 
         <i>   <b>Qianyu Zhou</b>, Zhengyang Feng, Qiqi Gu, Guangliang  Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma. </i><br> 
           Computer Vision and Image Understanding (<b>CVIU</b>), vol. 221, no. C, pp. 103448-103460, 2022. <br>
   [<a href="https://www.sciencedirect.com/science/article/pii/S1077314222000625">paper</a>]
   [<a href="https://arxiv.org/pdf/2004.08878.pdf">arxiv</a>]
   [<a href="https://www.sciencedirect.com/science/article/pii/S1077314222000625">DOI</a>]
   [<a href="bibs/CVIU_2022_UACR.txt">bib</a>] 
   </font>
   </p> </li>
  
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Domain Adaptive Semantic Segmentation via Regional Contrastive Consistency Regularization <br> 
         <i>   <b>Qianyu Zhou</b>, Chuyun Zhuang,  Ran Yi, Xuequan Lu, Lizhuang Ma. </i><br> 
         IEEE International Conference on Multimedia and Expo (<b>ICME</b>), July, 2022 (Oral Presentation). <br>
   [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9859793">paper</a>]
   [<a href="https://arxiv.org/pdf/2110.05170">arxiv</a>]
   [<a href="https://ieeexplore.ieee.org/document/9859793">DOI</a>]
   [<a href="https://github.com/qianyuzqy/RCCR">code</a>]
   [<a href="bibs/ICME_2022_RCCR.txt">bib</a>] 
   </font>
   </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            DMT: Dynamic Mutual Training for Semi-Supervised Learning <br> 
         <i>   Zhengyang Feng*, <b>Qianyu Zhou*</b>, Qiqi Gu, Xin Tan, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma. </i><br> 
         Patter Recognition (<b>PR</b>), vol. 130, no. C, pp. 108777-108789, 2022. <br>
   [<a href="https://www.sciencedirect.com/science/article/pii/S0031320322002588">paper</a>]
   [<a href="https://arxiv.org/pdf/2004.08514.pdf">arxiv</a>]
   [<a href="https://www.sciencedirect.com/science/article/pii/S0031320322002588">DOI</a>]
   [<a href="https://github.com/voldemortX/DST-CBC">code</a>]
   [<a href="bibs/PR_2022_DMT.txt">bib</a>]
   </font>
   </p> </li>


</ul>
<h3>2021:</h3> 
<ul>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            End-to-End Video Object Detection with Spatial-Temporal Transformers <br> 
         <i>   Lu He*, <b>Qianyu Zhou*</b>, Xiangtai Li*, Li Niu, Guangliang Cheng, Xiao Li, Wenxuan Liu, Yunhai Tong, Lizhuang Ma, Liqing Zhang. </i><br> 
         The 29th ACM International Conference on Multimedia (<b>ACM MM</b>), pp. 1507-1516, October, 2021. <br>
   [<a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475285">paper</a>]
   [<a href="https://arxiv.org/pdf/2105.10920.pdf">arxiv</a>]
   [<a href="https://dl.acm.org/doi/10.1145/3474085.3475285">DOI</a>]
   [<a href="https://github.com/SJTU-LuHe/TransVOD">code</a>] 
   [<a href="bibs/MM_2021_TransVOD.txt">bib</a>]
   </font>
   </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            PIT: Position-Invariant Transform for Cross-FoV Domain Adaptation <br> 
         <i>   Qiqi Gu*, <b>Qianyu Zhou*</b>, Minghao Xu, Zhengyang Feng, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma. </i><br> 
         IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), pp. 8741-8750, October, 2021. <br>
   [<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Gu_PIT_Position-Invariant_Transform_for_Cross-FoV_Domain_Adaptation_ICCV_2021_paper.pdf">paper</a>]
   [<a href="https://arxiv.org/pdf/2108.07142.pdf">arxiv</a>]
   [<a href="https://ieeexplore.ieee.org/document/9711500">DOI</a>] 
   [<a href="https://github.com/sheepooo/PIT-Position-Invariant-Transform">code</a>]
   [<a href="bibs/ICCV_2021_PIT.txt">bib</a>]
   </font>
   </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Label-free Regional Consistency for Image-to-Image Translation <br> 
         <i>   Shaohua Guo, <b>Qianyu Zhou<sup>†</sup></b>, Zhou Ye, Qiqi Gu, Junshu Tang, Zhengyang Feng, Lizhuang Ma<sup>†</sup>. </i><br> 
         IEEE International Conference on Multimedia and Expo (<b>ICME</b>), July, 2021. <br>
   [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9428211">paper</a>]
   [<a href="https://ieeexplore.ieee.org/document/9428211">DOI</a>]
   [<a href="bibs/ICME_2021_LFRC.txt">bib</a>]
   </font>
   </p> </li>
   
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Semi-Supervised 3D Object Detection Via Adaptive Pseudo-Labeling <br> 
         <i>  Hongyi Xu, Fengqi Liu, <b>Qianyu Zhou<sup>†</sup></b>, Jinkun Hao, Zhijie Cao, Zhengyang Feng, Lizhuang Ma<sup>†</sup>. </i><br> 
         IEEE International Conference on Image Processing (<b>ICIP</b>), September, 2021. <br>
   [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9506421">paper</a>]
   [<a href="https://arxiv.org/pdf/2108.06649.pdf">arxiv</a>]
   [<a href="https://doi.org/10.1109/ICIP42928.2021.9506421">DOI</a>]
   [<a href="bibs/ICIP_2021_SS3D.txt">bib</a>]
   </font>

</ul>
</script>

<script>showPubs(0);</script>
<script>var scroll = new SmoothScroll('a[href*="#"]', {speed: 1000});</script>


<br>
<h2><font face="Arial"> Education </font></h2>
<div id="education">
<!-- <a name="Experience" /> -->
<ul>
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Ph.D, <a href="https://www.cs.sjtu.edu.cn/en/" target="_blank" style="color: black;"> Department of Computer Science and Engineering</a>, <a href="https://en.sjtu.edu.cn/" target="_blank" style="color: black;">Shanghai Jiao Tong University</a>. (Sep. 2019 - Present)<br>
            Memeber of <a href="https://xsb.seiee.sjtu.edu.cn/xsb/info/35105.htm" target="_blank" style="color: black;"> Wenjun Wu AI Honored Ph.D Class</a> (Top 1%), <a href="https://ai.sjtu.edu.cn/" target="_blank" style="color: black;"> AI Institute</a>, <a href="https://en.sjtu.edu.cn/" target="_blank" style="color: black;">Shanghai Jiao Tong University</a>; <br>
            Memeber of <a href="https://www.gs.sjtu.edu.cn/post/detail/Z3MxNDc2" target="_blank" style="color: black;"> Zhiyuan Honored Ph.D Program</a> (The Highest Honor) in <a href="https://en.sjtu.edu.cn/" target="_blank" style="color: black;">Shanghai Jiao Tong University</a>; <br>
            Advised by <a href="https://scholar.google.com.hk/citations?user=yd58y_0AAAAJ&hl=en" target="_blank" style="color: black;">Prof. Lizhuang Ma</a> and Dr. <a href="https://shijianping.me/" target="_blank" style="color: black;"> Jianping Shi</a> <br>
   </font>
     </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            B.Sc, <a href="http://ccst.jlu.edu.cn/" target="_blank" style="color: black;">College of Computer Science and Technology</a>, <a href="http://global.jlu.edu.cn/" target="_blank" style="color: black;">Jilin University</a>. (Aug. 2015 - Jun. 2019)<br>
            Top Ten Honorary Undergraduates (The Highest Honor) in Jilin University;<br> 
        <!--     Advised by <a href="http://ccst.jlu.edu.cn/info/1200/17274.htm" target="_blank" style="color: black;">Prof. Yanheng Liu</a> and <a href="https://sungeng207.github.io/" target="_blank" style="color: black;">Prof. Geng Sun</a> <br> -->
   </font>
     </p> </li>


</ul>
</div>


<h2><font face="Arial"> Experience </font></h2>
<div id="experience">
<ul>
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Research Intern at <a href="https://www.catl.com/en/">Contemporary Amperex Technology Co., Ltd (CATL)</a>, Ningde, P.R.China. (May. 2023 - Aug. 2023)<br> 
         Worked on surface defect detection, quality inspection for industrial manufacturing.<br> 
         Collaborators: <a href="https://hujiecpp.github.io/">Jie Hu</a> and <a href="https://scholar.google.com.au/citations?user=yw-rcj4AAAAJ&hl=en">Guannan Jiang</a> <br>
   </font>
     </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Research Intern at <a href="https://open.youtu.qq.com/#/open">Youtu Lab</a>, <a href="https://www.tencent.com/en-us/index.html">Tencent</a>, Shanghai, P.R.China. (July. 2021 - Nov. 2022)<br> 
         Worked on face anti-spoofing, biometrics security.<br> 
         Mentor: <a href="https://sndler.github.io/">Taiping Yao</a> and <a href="https://scholar.google.com.hk/citations?user=i2ah3-wAAAAJ&hl=en">Ke-Yue Zhang</a> <br>
   </font>
     </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Research Intern at <a href="https://www.sensetime.com/en">Sensetime Reserch</a>, Beijing & Shanghai, P.R.China. (July. 2019 - Mar. 2021)<br> 
         Worked on scene understanding, autonomous driving. <br> 
         Mentor: <a href="https://scholar.google.com.hk/citations?user=FToOC-wAAAAJ&hl=en">Guangliang Cheng</a> and <a href="https://scholar.google.com.hk/citations?user=mwsxrm4AAAAJ&hl=en">Jianping Shi</a> <br>
   </font>
     </p> </li>

</ul>
</div>




<!-- <h2><font face="Arial"> Experience </h2>
<ul style="list-style-type:none">
<p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">
<li>Research Intern, <a href="https://www.catl.com/en/">Contemporary Amperex Technology Co., Ltd </a>  (Mentor: <a href="https://hujiecpp.github.io/">Jie Hu</a> and <a href="https://scholar.google.com.au/citations?user=yw-rcj4AAAAJ&hl=en">Guannan Jiang</a>) <div style="float:right; text-align:right">May. 2023 - Aug. 2023</div><br>
<p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">
<li>Remote Intern, <a href="http://rongcheer.com/enproducts.asp">Rongcheer Industrial Technology Co., Ltd </a> (Manager: Yan Tang and <a href="http://rongcheer.com/NewsShow.asp?Bid=32">Wenbing Zhu</a>) <div style="float:right; text-align:right">April. 2023-May. 2023</div><br>
<li>Research Intern, <a href="https://open.youtu.qq.com/#/open">Youtu Lab</a>, <a href="https://www.tencent.com/en-us/index.html">Tencent</a> (Mentor: <a href="https://sndler.github.io/">Taiping Yao</a> and <a href="https://scholar.google.com.hk/citations?user=i2ah3-wAAAAJ&hl=en">Ke-Yue Zhang</a>) <div style="float:right; text-align:right">July. 2021 - Nov. 2022</div><br>
<li>Research Intern, <a href="https://www.sensetime.com/en">Sensetime Reserch</a> (Mentor: <a href="https://scholar.google.com.hk/citations?user=FToOC-wAAAAJ&hl=en">Guangliang Cheng</a> and <a href="https://scholar.google.com.hk/citations?user=mwsxrm4AAAAJ&hl=en">Jianping Shi</a>)<div style="float:right; text-align:right">July. 2019 - Mar. 2021</div><br>
</p>
</ul> -->


<h2><font face="Arial"> Academic Services </font></h2>
<div id="service">
<!-- <a name="Services" /> -->
<ul style="list-style-type:none"> 
	 <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
         <strong> Journal Reviewer </strong> <br> </font> </p> 
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px; color: black">
        <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" style="color: black;">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) </a> </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
         <a href="https://www.springer.com/journal/11263" style="color: black;">International Journal of Computer Vision (IJCV)</a> </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83" style="color: black;"> IEEE Transactions on Image Processing (TIP) </a> </p>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046" style="color: black;"> IEEE Transactions on Multimedia (TMM) </a> </p>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76" style="color: black;"> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) </a> </p>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        <a href="https://www.sciencedirect.com/journal/information-fusion" style="color: black;">Information Fusion (INFFUS) </a> </p>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        <a href="https://www.sciencedirect.com/journal/neurocomputing/" style="color: black;">Neurocomputing </a> </p>
    </li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        <a href="https://www.frontiersin.org/journals/neuroscience" style="color: black;">Frontiers in Neuroscience </a> </p>
    </li>
	 <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
         <strong> Conference Reviewer </strong> <br> </font> </p> 
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022 - 2024 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE International Conference on Computer Vision (ICCV), 2023 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        European Conference on Computer Vision (ECCV), 2022, 2024 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        International Conference on Machine Learning (ICML), 2024 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        AAAI Conference on Artificial Intelligence (AAAI), 2023 - 2024 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        ACM International Conference on Multimedia (ACM MM), 2023 - 2024 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE International Conference on Multimedia and Expo (ICME), 2023 - 2024 </p></li>
</ul>
</div>


<h2><font face="Arial"> Honors &amp; Awards </h2>
<div id="honors">
<ul style="list-style-type:none">
<p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">
<li>Zhiyuan Honored Ph.D Fellowship, Shanghai Jiao Tong University <div style="float:right; text-align:right">2019 - 2024</div><br>
<li>Wenjun wu AI Honored Ph.D Fellowship, Shanghai Jiao Tong University <div style="float:right; text-align:right">2019 - 2024</div><br>
<li>Yuanqing Yang Ph.D Fellowship, Shanghai Jiao Tong University <div style="float:right; text-align:right">2023</div><br>
<li>Best Paper Award in CAD/Graphics 2023 <div style="float:right; text-align:right">2023</div><br>  
<li>Top 3% Paper Recognition of all papers accepted at ICASSP 2023 <div style="float:right; text-align:right">2023</div><br>
<li>First Class Scholarship of DMCV Lab, Shanghai Jiao Tong University <div style="float:right; text-align:right">2022</div><br>
<li>National Scholarship, Ministry of Education of P.R. China<div style="float:right; text-align:right">2016 - 2018</div><br>
<li>President Scholarship of Jilin University<div style="float:right; text-align:right">2019</div><br>
<li>Outstanding Graduates of Jilin University<div style="float:right; text-align:right">2019</div><br>
<li>Top Ten Honorary Undergraduates (The Highest Honor), Jilin University <div style="float:right; text-align:right">2019</div><br>
</p>
</ul>
</div>





<br>
 <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=x6jtKeC44vFualcc13VnRDgl0HH2yt7AUpWIYw2ox54&cl=ffffff&w=300&t=tt"></script>  
 <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha3848gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>
<script src="script.js"></script><table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> 
<div id="footer">
	<div id="footer-text"></div>
</div>
	<p></p><center>
        <br>
            © Qianyu Zhou | Last updated: 05/2024
        </center><p></p>

</b></b></b></div><b><b><b>

</b></b></b></body>
<!-- {% include analytics.html %}
 -->
</html>

